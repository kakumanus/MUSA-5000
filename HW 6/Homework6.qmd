---
title: "Homework 6: IMDB Text Mining & Sentiment Analysis"
author: "Yiming Cao, Sujan Kakumanu, Angel Sanaa Rutherford"
date: December 12 2025
number-sections: true
execute:
  cache: true
format:
  pdf:
    include-in-header:
      text: |
        \usepackage{makecell}
---
```{r setup}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures
options(scipen = 999)

# Packages
if(!require(pacman)){install.packages("pacman"); library(pacman, quietly = T)}
p_load(wordcloud, tm, SnowballC, words, NbClust, stringr, dplyr, syuzhet)

```

```{r load-preprocess-data}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures

# myCorpus <- tm::VCorpus(VectorSource(sapply("IMDB_Dataset_short.csv", readLines)))
# 
# myCorpus <- tm_map(myCorpus, content_transformer(tolower))

my_data <- read.csv("IMDB_Dataset_short.csv", stringsAsFactors = FALSE)

my_text_source <- VectorSource(my_data$review)

myCorpus <- VCorpus(my_text_source)

myCorpus <- tm::tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removePunctuation)

myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))

myCorpus <- tm_map(myCorpus, removeWords,c("I", "br", "You,", "The", "A", "It"))

cat(content(myCorpus[[2]])[0:1], sep = "\n")
```

```{r document-term-matrix}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures

dtm_cleaned <- DocumentTermMatrix(myCorpus)
tm::inspect(dtm_cleaned)

m <- as.matrix(dtm_cleaned)
dim(m)
```

```{r term-distribution}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures

cs <- as.matrix(colSums(m))             #How many times each term appears across all documents (texts)
rownames(cs) <- dtm_cleaned$dimnames$Terms

hist(cs, breaks=100)
```

```{r wordcloud}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures

tab <- as.matrix(table(cs))
wordcloud(myCorpus, min.freq=500)
```
```{r remove-infrequent}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures

variables_to_remove <- cs < 10000

# Subset matrix frame, excluding those variables
m_subset <- m[, !variables_to_remove]

#Some books are longer, others are shorter. Let's divide the frequencies by the total number of words (after processing) in each book.
m_fin <- m_subset/rowSums(m)

#Let's scale (normalize) each of the variables (relative frequency)
m_scale <- scale(m_fin)
```

```{r sentiment}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures
nrc <- syuzhet::get_sentiment_dictionary(dictionary="nrc")
head(nrc, n=20L)
```

```{r review-sentiment-analysis}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures

review <- as.data.frame(m[1,])
review$Term <- as.vector(rownames(review))

colnames(review)[1] = "Term_Frequency"
rownames(review) <- 1:nrow(review)

nrc_sentiment <- get_nrc_sentiment(review$Term)

Review_Sentiment <- cbind(review, nrc_sentiment)

cols_to_multiply <- names(Review_Sentiment)[3:12]

# Multiply the last ten columns (sentiments) by the first column (Term_Frequency)
Review_Sentiment[, cols_to_multiply] <- Review_Sentiment[, cols_to_multiply] * Review_Sentiment$Term_Frequency

Review_Sentiment_Total <- t(as.matrix(colSums(Review_Sentiment[,-1:-2])))
barplot(Review_Sentiment_Total, las=2, ylab='Count', main='Sentiment Scores')
```

# Introduction

In this analysis, we performed text-mining techniques to movie reviews from the Internet Movie Database (IMDb) in order to quantify and visualize word trends and emotional tones across reviews. Text-mining combines data cleaning and language processing techniques, enabling researchers to systematically analyze unstructured text for meaningful patterns such as term frequency and emotional sentiments. This approach combines the ease of decreased manual effort with nuance in understanding narratives and perspectives. 

# Methods

## Data Preprocessing

We began by importing the IMDb dataset csv into R and converting the review column into a corpus object using the `tm` package. The `VectorSource` function was called in order to treat every review as a separate document. The result was a corpus which, in this context, streamlines analysis by serving as a repository of the text documents. The corpus was then preprocessed to ensure uniformity and remove noise. Specifically, all entries were transformed to lowercase, numbers and punctuation were removed, and common English stopwords were excluded. In addition, a small set of self-defined stop and non-english words ("I", "br", "You,", "The", "A", "It") were removed after additional data exploration to further reduce noise.

## Word Cloud Creation

After preprocessing we created a document term matrix (DTM) which represents the frequency of terms across all documents. In this matrix, each row corresponds with a document, each column corresponds to a unique term, and the cell values represent the number of times the term itself appears in a given document. 

From this DTM, two visuals were created to represent the frequency of terms: a histogram and a word cloud. In a word cloud visualization, words are displayed in font sizes proportional to the their frequency, allowing words repeated more frequently to be more visible. We used the `wordcloud` function to create our visual which takes a specified threshold for which words to display based on frequency. In analysis, we chose to only display words that appeared more than 500 times to ensure variation but also to reduce noise.

## Sentiment Analysis

Sentiment analysis was conducted to identify the emotional tone present within the IMDb review corpus. After converting the cleaned text into a document-term matrix, we used the NRC Emotion Lexicon, implemented through the syuzhet package, to map individual terms to ten emotion categories: anger, anticipation, disgust, fear, joy, sadness, surprise, trust, positive, and negative. A lexicon-based approach was chosen because it provides interpretable emotional classifications and is well suited for short and medium-length texts such as movie reviews.

To generate sentiment scores, we first extracted all terms appearing in a selected review along with their corresponding frequencies. Each word was then matched against the NRC lexicon to determine which emotions it contributes to. Because words may appear multiple times within the same review, emotional scores were weighted by term frequency to more accurately capture the intensity of expressed sentiment. After multiplying each emotion indicator by word frequency, we summed the results across all terms to produce an aggregate sentiment profile for the review. This process allowed us to quantify the emotional composition of the text and visualize it through a barplot illustrating the relative prominence of different emotions. Overall, the sentiment analysis approach provides a straightforward and interpretable way to characterize how reviewers express feelings toward the films they describe.

# Results

## Word Cloud

### Preprocessing and Document-Term Matrix

After loading the IMDb review dataset, we applied a series of preprocessing steps to standardize the text data. These procedures included converting all characters to lowercase, removing numbers and punctuation, and eliminating English stopwords. Additional high-frequency but uninformative tokens such as “I,” “br,” “you,” “the,” “a,” and “it” were removed to ensure that the final corpus emphasized meaningful, content-bearing words. This process resulted in clean textual entries consisting primarily of descriptive terms and phrases relevant to the reviews.

```{r load-preprocess-data1}
#| echo: false
#| message: false
#| warning: false
library(knitr)
library(kableExtra)
library(stringr)

my_data <- read.csv("IMDB_Dataset_short.csv", stringsAsFactors = FALSE)

my_text_source <- VectorSource(my_data$review)
myCorpus <- VCorpus(my_text_source)

myCorpus <- tm_map(myCorpus, content_transformer(tolower))

myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, removeWords, c("I", "br", "you", "The", "A", "It"))

sample_ids <- 1:3
original_text <- my_data$review[sample_ids]
cleaned_text <- sapply(myCorpus[sample_ids], content)


original_text_short <- str_trunc(original_text, 100)
cleaned_text_short <- str_trunc(cleaned_text, 100)

preprocess_sample <- data.frame(
  Document_ID = sample_ids,
  Original_Text = str_trunc(original_text_short, width = 40, ellipsis = "..."),
  Cleaned_Text = str_trunc(cleaned_text_short, width = 40, ellipsis = "...")
)

kable(
preprocess_sample,
caption = "Examples of Original and Cleaned IMDb Reviews",
align = "l"
) %>%
kable_styling(
full_width = FALSE,
position = "left",
latex_options = "hold_position"
)
```

A document-term matrix (DTM) was then constructed to quantify the frequency of each term across the corpus. The DTM contains 199 documents and 7,937 unique terms with an overall sparsity of 99%, which is typical of natural language data. Inspecting sample rows of the matrix reveals that commonly used film-related words—such as “film,” “movie,” “story,” and “good”—appear across many reviews, whereas most other terms occur only once or a few times. This reinforces the long-tailed nature of the dataset, where a small number of general descriptive words dominate, and thousands of low-frequency terms reflect specific opinions or contexts unique to individual reviews.

```{r document-term-matrix1}
#| echo: false
#| message: false
#| warning: false

library(knitr)
library(kableExtra)

dtm_cleaned <- DocumentTermMatrix(myCorpus)

m <- as.matrix(dtm_cleaned)

n_docs  <- nrow(m)
n_terms <- ncol(m)
nnzero  <- sum(m > 0)  # number of non-zero entries
sparsity <- 1 - nnzero / (n_docs * n_terms)

dtm_summary <- data.frame(
Metric = c("Number of Documents", "Number of Terms", "Non-zero Entries", "Sparsity"),
Value  = c(
n_docs,
n_terms,
nnzero,
paste0(round(100 * sparsity, 2), "%")
)
)

kable(
dtm_summary,
caption = "Document-Term Matrix Summary",
align = "l"
) %>%
kable_styling(
full_width = FALSE,
position = "left",
latex_options = "hold_position"
)

dtm_sample <- m[1:5, 1:10]

```

### Term Frequency Distribution

The histogram of term frequencies further illustrates this pattern: the vast majority of words fall into the lowest frequency bin, with only a small number appearing more than 20 or 30 times. Such a distribution is expected in movie reviews, where each author introduces unique vocabulary while still relying on a shared set of evaluative and narrative descriptors. This distribution directly influences the terms that dominate the word cloud visualization.

```{r term-distribution1}
#| echo: false
#| message: false
#| warning: false

cs <- as.matrix(colSums(m))             #How many times each term appears across all documents (texts)
rownames(cs) <- dtm_cleaned$dimnames$Terms

hist(cs, breaks=100)
```

### Word Cloud

The word cloud highlights the terms that occur most frequently across the corpus. Larger words, such as “many,” “performance,” “plot,” “game,” “classic,” and “hotel,” indicate repeated appearance in reviews and reflect common themes related to storytelling, acting quality, and genre conventions. Additionally, expressive adjectives such as “difficult,” “appropriate,” “fabulous,” and “unexpectedly” suggest that reviewers frequently rely on emotional and descriptive language to articulate their reactions to the films.

Overall, the combination of the preprocessing results, term frequency distribution, and word cloud visualization offers a coherent picture of the lexical patterns present in the dataset. These findings demonstrate the diversity of vocabulary used by reviewers and highlight the central descriptive themes that recur throughout the IMDb corpus.

```{r wordcloud1}
#| echo: false
#| message: false
#| warning: false

tab <- as.matrix(table(cs))
wordcloud(myCorpus, min.freq=500)
```


## Sentiment Analysis

The sentiment analysis was conducted on the first review in the IMDB dataset using the NRC lexicon, which categorizes words into eight emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, trust) and two sentiments (negative, positive). Each term in the review was matched against the NRC sentiment dictionary, and the sentiment scores were weighted by the frequency of each term's appearance in the review.

The bar plot below displays the total sentiment scores across all ten categories. The analysis shows that negative sentiment dominates this review, with a count of approximately 21 compared to positive sentiment at around 8. Among the emotions, fear, anger, and sadness are most prevalent, while trust is the highest-scoring positive emotion.

```{r review-sentiment-analysis-results}
#| echo: false
#| message: false
#| warning: false

review <- as.data.frame(m[1,])
review$Term <- as.vector(rownames(review))

colnames(review)[1] = "Term_Frequency"
rownames(review) <- 1:nrow(review)

nrc_sentiment <- get_nrc_sentiment(review$Term)

Review_Sentiment <- cbind(review, nrc_sentiment)

cols_to_multiply <- names(Review_Sentiment)[3:12]

# Multiply the last ten columns (sentiments) by the first column (Term_Frequency)
Review_Sentiment[, cols_to_multiply] <- Review_Sentiment[, cols_to_multiply] * Review_Sentiment$Term_Frequency

Review_Sentiment_Total <- t(as.matrix(colSums(Review_Sentiment[,-1:-2])))
barplot(Review_Sentiment_Total, las=2, ylab='Count', main='Sentiment Scores in an IMDB Movie Review')
```

However, visual inspection of the actual review reveals it is positive in nature. This highlights a key limitation of lexicon-based sentiment analysis: it does not account for context. The high scores for fear, anger, and sadness likely reflect the reviewer describing the film's plot — discussing scary or tense scenes — rather than expressing dissatisfaction with the movie. This approach accounts for term frequency but cannot distinguish between describing negative content positively versus expressing genuine criticism of the film.

# Discussion

The findings from this text mining and sentiment analysis of IMDb movie reviews reveal important insights into how viewers express their opinions about films, while also highlighting challenges in sentiment classification. The word cloud visualization demonstrates that reviewers consistently use vocabulary focused on the nature of film ("plot," "story", "performance", etc.), and evaluative language ("classic," "fabulous"). This consistency in terminology could prove valuable for those seeking to understand which aspects of movies resonate most strongly with viewers and generate discussion.

However, the sentiment analysis results underscore a limitation of lexicon-based approaches: the inability to distinguish between describing negative content and expressing negative sentiment about the film itself. As demonstrated with the first review, high scores for fear, anger, and sadness reflected plot descriptions of a thriller rather than criticism of the movie. Future analyses could address this limitation through several approaches: implementing more sophisticated natural language processing techniques that account for context and negation, comparing sentiment scores between positive and negative reviews to identify distinguishing patterns, or doing some analysis to separate discussion of film content from evaluative commentary. Additionally, examining how sentiment patterns differ across genres could reveal whether certain types of films typically produce misleading sentiment scores, thereby refining our understanding of when simple lexicon-based methods are sufficient versus when more complex contextual analysis is necessary.
