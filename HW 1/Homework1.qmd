---
title: "Homework 1: Using OLS Regression to Predict Median House Values in Philadelphia"
author: "Yiming Cao, Sujan Kakumanu, Angel Sanaa Rutherford"
date: October 15 2025
number-sections: true
format: pdf
---
```{r setup}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures
options(scipen = 999)
library(ggplot2)             
library(dplyr)
library(sf)
library(ggplot2)
library(patchwork)
library(MASS)
library(caret)
```

```{r exploratory-data-analysis}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures
regression_data <- read.csv("./RegressionData.csv")

hist(regression_data$MEDHVAL)
hist(regression_data$PCTBACHMOR)
hist(regression_data$NBELPOV100)
hist(regression_data$PCTVACANT)
hist(regression_data$PCTSINGLES)

plot(regression_data$PCTBACHMOR, regression_data$MEDHVAL)
plot(regression_data$NBELPOV100, regression_data$MEDHVAL)
plot(regression_data$PCTVACANT, regression_data$MEDHVAL)
plot(regression_data$PCTSINGLES, regression_data$MEDHVAL)

mean_medhval <- mean(regression_data$MEDHVAL)
mean_pctbachmor <- mean(regression_data$PCTBACHMOR)
mean_nbelpov100 <- mean(regression_data$NBELPOV100)
mean_pctvacant <- mean(regression_data$PCTVACANT)
mean_pctsingles <- mean(regression_data$PCTSINGLES)

sd_medhval <- sd(regression_data$MEDHVAL)
sd_pctbachmor <- sd(regression_data$PCTBACHMOR)
sd_nbelpov100 <- sd(regression_data$NBELPOV100)
sd_pctvacant <- sd(regression_data$PCTVACANT)
sd_pctsingles <- sd(regression_data$PCTSINGLES)
```

```{r exploratory-data-analysis-log}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures
regression_data$LNMEDHVAL<-log(regression_data$MEDHVAL)

regression_data$LNPCTBACHMOR<-log(1+regression_data$PCTBACHMOR)
regression_data$LNNBELPOV100<-log(1+regression_data$NBELPOV100)
regression_data$LNPCTVACANT<-log(1+regression_data$PCTVACANT)
regression_data$LNPCTSINGLES<-log(1+regression_data$PCTSINGLES)

hist(regression_data$LNMEDHVAL)
hist(regression_data$LNPCTBACHMOR)
hist(regression_data$LNNBELPOV100)
hist(regression_data$LNPCTVACANT)
hist(regression_data$LNPCTSINGLES)

plot(regression_data$PCTBACHMOR, regression_data$LNMEDHVAL)
plot(regression_data$LNNBELPOV100, regression_data$LNMEDHVAL)
plot(regression_data$PCTVACANT, regression_data$LNMEDHVAL)
plot(regression_data$PCTSINGLES, regression_data$LNMEDHVAL)

cor(regression_data$PCTBACHMOR, regression_data$LNMEDHVAL, method="pearson")
cor(regression_data$LNNBELPOV100, regression_data$LNMEDHVAL, method="pearson")
cor(regression_data$PCTVACANT, regression_data$LNMEDHVAL, method="pearson")
cor(regression_data$PCTSINGLES, regression_data$LNMEDHVAL, method="pearson")

trimmed_regression_data <- regression_data %>% dplyr::select(PCTBACHMOR, LNNBELPOV100, PCTVACANT, LNMEDHVAL, PCTSINGLES)
#remove LNMEDHVAL in final product
cor(trimmed_regression_data)
```

```{r exploratory-data-analysis-mapping}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures
Regression_shpData <- st_read("./Lecture 1 - RegressionData.shp")

ggplot(Regression_shpData) +
  geom_sf(aes(fill =  LNMEDHVAL), color = NA) +
  scale_fill_viridis_c(option = "plasma")+
  labs(
    title = "Log Transformed Median House Value by Census Block Groups",
    subtitle = "Philadelphia"
  ) +
  theme_minimal()

base_theme <- theme_minimal() +
  theme(
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.title = element_text(size = 6, margin = margin(b = 4))  # smaller + some breathing room
  )

p1 <- ggplot(Regression_shpData) +
  geom_sf(aes(fill = PCTVACANT), color = NA) +
  scale_fill_viridis_c(option = "plasma", na.value = "grey80") +
  labs(title = "Percent of Housing Units that are Vacant,\n at Block Group", fill = "Value") +
  theme_minimal() +
  theme(axis.text = element_blank(), axis.title = element_blank(), panel.grid = element_blank()) +
  base_theme

p2 <- ggplot(Regression_shpData) +
  geom_sf(aes(fill = PCTSINGLES), color = NA) +
  scale_fill_viridis_c(option = "plasma", na.value = "grey80") +
  labs(title = "Percent of Housing Units that are Single Family Detatched,\n at Block Group", fill = "Value") +
  theme_minimal() +
  theme(axis.text = element_blank(), axis.title = element_blank(), panel.grid = element_blank()) +
  base_theme

p3 <- ggplot(Regression_shpData) +
  geom_sf(aes(fill = PCTBACHMOR), color = NA) +
  scale_fill_viridis_c(option = "plasma", na.value = "grey80") +
  labs(title = "Percent of Housing Units that have at least Bachelor's Degree,\n at Block Group", fill = "Value") +
  theme_minimal() +
  theme(axis.text = element_blank(), axis.title = element_blank(), panel.grid = element_blank()) +
  base_theme

p4 <- ggplot(Regression_shpData) +
  geom_sf(aes(fill = LNNBELPOV), color = NA) +
  scale_fill_viridis_c(option = "plasma", na.value = "grey80") +
  labs(title = "Log Transformed Number of Households Below 100% Poverty Level,\n at Block Group", fill = "Value") +
  theme_minimal() +
  theme(axis.text = element_blank(), axis.title = element_blank(), panel.grid = element_blank()) +
  base_theme

(p1 | p2) / (p3 | p4)
```

```{r multiple-regression-analysis}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures
reg1 <- lm(LNMEDHVAL ~ PCTVACANT + PCTSINGLES + PCTBACHMOR + LNNBELPOV, data=Regression_shpData)

summary(reg1)

anova(reg1)

Regression_shpData$predvals <- fitted(reg1) 

Regression_shpData$resids <- residuals(reg1)

Regression_shpData$stdres <- rstandard(reg1)

plot(Regression_shpData$predvals, Regression_shpData$stdres)

```

```{r step}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures
step <- stepAIC(reg1, direction="both")

step$anova
```

```{r k-fold-cv}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures
train_control <- trainControl(method = "cv", number = 5)

cv_model <- train(LNMEDHVAL ~ PCTVACANT + PCTSINGLES + PCTBACHMOR + LNNBELPOV,
                  data = Regression_shpData,
                  method = "lm",
                  trControl = train_control)
cv_model

cv_model_2 <- train(LNMEDHVAL ~ PCTVACANT + MEDHHINC,
                  data = Regression_shpData,
                  method = "lm",
                  trControl = train_control)
cv_model_2
```

```{r std-residuals-charts}
#| echo: false
#| results: "hide" # Hide the output
#| message: false  # Hide messages
#| warning: false  # Hide warnings
#| fig.show: "hide" # Hide plots/figures
hist(Regression_shpData$stdres)

ggplot(Regression_shpData) +
  geom_sf(aes(fill =  stdres), color = NA) +
  scale_fill_viridis_c(option = "plasma")+
  labs(
    title = "",
    subtitle = ""
  ) +
  theme_minimal()
```

# Introduction

# Methods

## Data Cleaning

## Exploratory Data Analysis

## Multiple Regression Analysis

## Additional Analysis

###
Using the stepAIC() and step$anova command, we applied bidirectional stepwise regression to analyze the fit of our linear model. Stepwise regression determines the minimum number of predictors that yield the best model. Stepwise regression automatically selects or eliminates predictors, either forwards, backwards, or bidirectionally, based on some type of criteria that measures the goodness of fit. In this case, we are attempting to determine the predictor or combination of predictors that minimize the Akaike Information Criterion (AIC).
Stepwise regression, however, poses many limitations as it does not consider theoretical relevance of the predictors, may overlook alternative valid models, and runs the risk of excluding important predictors and including unimportant predictors, especially due to the numerous t-tests measuring whether the null hypothesis,  $\beta_k$ = 0, is true.

###
To perform cross-validation, we used the trainControl() function with the method parameter set to â€œcvâ€ (cross-validation) and the train() function with the method parameter set to â€œlmâ€ (linear model). Cross-validation is a technique that measures model performance unbiasedly by training the model on a select subgroup of observations and seeing how well it estimates deliberately excluded observations. K-fold cross validation where k=5, specifically, divides data sets into five non-overlapping folds and repeatedly uses four folds for training the model and one fold for validating the model so that each fold trains the model multiple times and validates the model once. This method ensures a modelâ€™s generalizability to new data and minimizes distortion by avoiding omitting and duplicating data in its measure of fit.  After all five iterations are complete, the Root Mean Squared Error (RMSE) of the model is returned as a measurement of the average magnitude of predicted residuals or errors between predicted values, $\hat{ð‘¦}_i$, of observation $i$, estimated by the modelâ€™s $\beta$ coefficient, and the actual value, $y_i$, of the validation set. The complete formula for RMSE is as follows: 
$$
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
$$
After performing k-fold cross-validation on two or more models, the RMSE of the models can be compared to determine which model has the best performance. A smaller RMSE indicates that the modelâ€™s predictions are, on average, closer to the actual values, and thus more representative of the data.

## Software Used

###
All data analysis was conducted using R. Within R, the following packages were used to perform data preparation, exploratory analysis, regression modeling, and visualization: ggplot, dplyr, sf, patchwork, MASS, and caret. 
 
# Results

## Exploratory Results

## Regression Results

## Regression Assumption Checks

### 
When assessing the relationship between various predictors and a dependent variable, we test whether the assumptions of multiple regressions are met to determine whether a linear model is appropriate for the data. The assumptions used to evaluate data include: a roughly linear relationship between each predictor and the outcome, observations that are independent and do not influence one another, homoscedasticity or consistent spread of residuals, the normality of residuals, especially for smaller samples, and no multicollinearity or linearity between predictors.

### 
```{r ii. predictor scatter plots}
#| echo: false
plot(regression_data$PCTBACHMOR, regression_data$MEDHVAL,
      main = "Median House Value by Percentage with Bachelors",
     xlab = "Percentage with Bachelors",
     ylab = "Median House Value")

plot(regression_data$NBELPOV100, regression_data$MEDHVAL,
     main = "Median House Value by Number Below Poverty",
     xlab = "Number Below Poverty",
     ylab = "Median House Value")

plot(regression_data$PCTVACANT, regression_data$MEDHVAL,
     main = "Median House Value by Percentage Vacant",
     xlab = "Percentage Vacant",
     ylab = "Median House Value")

plot(regression_data$PCTSINGLES, regression_data$MEDHVAL,
     main = "Median House Value by Percentage of Singles",
     xlab = "Percentage",
     ylab = "Median House Value")
```

### 
```{r iii. std residuals histogram}
#| echo: false
hist(Regression_shpData$stdres,
     main = "Histogram of Standardized Regression Residuals",
     xlab = "Standardized Residuals",
     ylab = "Frequency")
```

###  
```{r iv. std residual scatter plot}
#| echo: false
plot(Regression_shpData$predvals, Regression_shpData$stdres,
     main = "Standardized Residuals By Predicted Values",
     xlab = "Predicted Values",
     ylab = "Standardized Residuals")
```

###  

### 
```{r vi. std residual choropleth}
#| echo: false
ggplot(Regression_shpData) +
  geom_sf(aes(fill =  stdres), color = NA) +
  scale_fill_viridis_c(option = "plasma", name = "Standardized Residuals")+
  labs(
    title = "Map of Standardized Regression Residuals",
    subtitle = ""
  ) +
  theme_void()
```

## Additional Models

### 
```{r i. stepwise results}
#| echo: false
step <- stepAIC(reg1, direction="both")

step$anova
```
Our initial model before performing stepwise regression:
$$
\text{LNMEDHVAL} \sim \text{PCTVACANT} + \text{PCTSINGLES} + \text{PCTBACHMOR} + \text{LNNBELPOV}
$$
As mentioned earlier, stepwise regression based on AIC evaluates whether a predictor improves the model fit by reducing the AIC. Our initial model had an AIC of -3448.162. When PCTSINGLES was removed, the AIC increased to â€“3432.3. When LNNBELPOV was removed, the AIC increased to â€“3365.0. When PCTVACANT was removed, the AIC increased to  â€“3102.8. When our last predictor PCTBACHMOR was removed, the AIC increased drastically to â€“2379.0. Since the removal of each predictor resulted in a higher AIC, all four initial predictors were retained in the final model. This suggests that the initial model was selected by stepwise regression as being a model that balances explanatory power and complexity.

### 
```{r ii. cross-validation}
#| echo: false
train_control <- trainControl(method = "cv", number = 5)

cv_model <- train(LNMEDHVAL ~ PCTVACANT + PCTSINGLES + PCTBACHMOR + LNNBELPOV,
                  data = Regression_shpData,
                  method = "lm",
                  trControl = train_control)
cv_model

cv_model_2 <- train(LNMEDHVAL ~ PCTVACANT + MEDHHINC,
                  data = Regression_shpData,
                  method = "lm",
                  trControl = train_control)
cv_model_2
```
We performed 5 fold cross-validation on two models, the first model including all of our original predictors and the second model being a reduced set of predictors that alternatively included MEDHHINC as a predictor. The second model is as follows:

$$
\text{LNMEDHVAL} \sim \text{PCTVACANT} + \text{MEDHHINC}
$$ 

The original model yielded a RMSE of 0.368 while the reduced model yielded a RMSE of 0.443, signaling that the additional predictors in the full model had better predictive power compared to  PCTVACANT and MEDHHINC alone. 

# Discussion & Limitations

